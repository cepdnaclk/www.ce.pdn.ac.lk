---
layout: page_news
id: 12
title: The Best Artifact Award at IPSN 2021
image: /news/images/1753118156.jpg
parent: News
link_url: https://doi.org/10.1145/3412382.3458269
link_caption: "Publication: DeepLight at IPSN Digital Library"

author: Ridma Jayasundara

published_date: 2021-05-24
updated_at: 2025-10-11 15:51:51+00:00
---

<p>We warmly congratulate Gihan Jayathilake, from the Department of Computer Engineering, for winning the best artifact award at the International Conference on Information Processing in Sensor Networks (IPSN) 2021 conference for his work on &ldquo;Deeplight&rdquo;. IPSN is a leading annual forum on research in networked sensing and control, broadly defined.</p>
<p>A paper co-authored by Gihan, titled &ldquo;DeepLight: Robust &amp; Unobtrusive Real-time Screen-Camera Communication for Real-World Displays" was accepted for IPSN 2021 (ACM/IEEE International Conference of Information Processing in Sensor Networks), which was held during 18-21 May 2021 in Nashville, Tennessee, USA. The conference had 105 submissions from all around the world and a 24% acceptance rate.</p>
<p>The team won the best artifact award at the conference. The award was introduced last year to encourage the sharing of code/data and to promote the credibility of the community&rsquo;s work. The evaluation criteria are (a) how well the code is written and (2) the impact/potential of the contribution to the community/society.</p>
<p>Deeplight is a novel screen-to-camera communication (SCC) system developed to enable real-world situations. The generic idea of such systems is to encode messages in computer screens to be decoded by a camera system. The basic task is to make these encodings imperceptible (so a human using the screen would not be disturbed by the messages being transmitted for the camera). The task becomes non-trivial because the image processing algorithm has to be able to decode the imperceptible encoding. A wide range of algorithms and system design challenges are detailed in the publication.</p>
<p>This project was done by Vu Tran (when he was a PhD student/postdoc in Singapore Management University) and Gihan Jayatilaka (when he was an intern at SMU and a final year undergraduate in the University of Peradeniya) under the supervision of their advisers Prof. Ashwin Ashok (Georgia State University) and Prof. Archan Misra (Singapore Management University).</p>
<p>DeepLight: Robust &amp; Unobtrusive Real-time Screen-Camera Communication for Real-World Displays Vu Tran (Singapore Management University), Gihan Jayatilaka (University of Peradeniya), Ashwin Ashok (Georgia State University), Archan Misra (Singapore Management University)</p>
<ul>
<li><a href="https://larc-cmu-smu.github.io/deeplight/">https://larc-cmu-smu.github.io/deeplight/</a></li>
<li><a href="https://ipsn.acm.org/2021/">https://ipsn.acm.org/2021/</a></li>
</ul>

<!-- Automated Update by GitHub Actions -->

<p>We warmly congratulate Gihan Jayathilake, from the Department of Computer Engineering for winning the best artifact award at the International Conference on Information Processing in Sensor Networks (IPSN) 2021 conference for his work on “Deeplight”. IPSN is a leading annual forum on research in networked sensing and control, broadly defined.</p><p>A paper co-authored by Gihan, titled “DeepLight: Robust &amp; Unobtrusive Real-time Screen-Camera Communication for Real-World Displays” was accepted for IPSN 2021 (ACM/IEEE International Conference of Information Processing in Sensor Networks) which was held during 18-21 May 2021 in Nashville, Tennessee, USA. The conference had 105 submissions from all around the world and a 24% acceptance rate.</p><p>The team won the best artifact award at the conference. The award was introduced last year to encourage sharing of code/data and to promote the credibility of the community’s work. The evaluation criteria are (a) how well presented the code is and (2) the impact/potential of the contribution to the community/society.</p><p>Deeplight is a novel screen-to-camera communication (SCC) system developed to enable real-world situations. The generic idea of such systems is to encode messages in computer screens to be decoded by a camera system. The basic task is to make these encodings imperceptible (so a human using the screen would not be disturbed by the messages being transmitted for the camera). The task becomes non-trivial because the image processing algorithm has to be able to decode the imperceptible encoding. A wide range of algorithm and system design challenges are detailed in the publication.</p><p>This project was done by Vu Tran (when he was a PhD student/postdoc in Singapore Management University) and Gihan Jayatilaka (when he was an intern at SMU and a final year undergraduate in the University of Peradeniya) under the supervision of their advisers Prof. Ashwin Ashok (Georgia State University) and Prof. Archan Misra (Singapore Management University).</p><p>DeepLight: Robust &amp; Unobtrusive Real-time Screen-Camera Communication for Real-World Displays Vu Tran (Singapore Management University), Gihan Jayatilaka (University of Peradeniya), Ashwin Ashok (Georgia State University), Archan Misra (Singapore Management University)</p><p>https://doi.org/10.1145/3412382.3458269</p><p>https://larc-cmu-smu.github.io/deeplight/</p><p>https://ipsn.acm.org/2021/</p>
